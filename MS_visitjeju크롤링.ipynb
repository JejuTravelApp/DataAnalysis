{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from urllib.parse import quote\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver  # 동적크롤링\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_scrapy_data : 전처리가 끝난 visitJeju의 API 전체 CSV\n",
    "data = pd.read_csv(\"Data/visit_jeju_scrapy_data.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>introduction</th>\n",
       "      <th>address</th>\n",
       "      <th>roadaddress</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phoneno</th>\n",
       "      <th>imgpath</th>\n",
       "      <th>tag</th>\n",
       "      <th>contentsid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미유</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>숲속 별장처럼 꾸며진 소품 가게</td>\n",
       "      <td>제주특별자치도 제주시 한림읍 옹포리 326-3</td>\n",
       "      <td>제주특별자치도 제주시 한림읍 한림상로 15-5</td>\n",
       "      <td>33.405636</td>\n",
       "      <td>126.256762</td>\n",
       "      <td>0507-1349-9322</td>\n",
       "      <td>https://api.cdn.visitjeju.net/photomng/imgpath...</td>\n",
       "      <td>핸드메이드소품, 키링, 우산, 한림, 옹포리, 소품샵, 지갑, 쇼핑</td>\n",
       "      <td>CNTS_200000000015086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>마야블루</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>마야블루는 제주 시내의 주택가 사이에 작은 간판으로 자신의 존재를 알리고 있다. 이...</td>\n",
       "      <td>제주특별자치도 제주시 노형동 1052-27</td>\n",
       "      <td>제주특별자치도 제주시 월랑로6길 21</td>\n",
       "      <td>33.489570</td>\n",
       "      <td>126.478593</td>\n",
       "      <td>010-8515-2470</td>\n",
       "      <td>https://api.cdn.visitjeju.net/photomng/imgpath...</td>\n",
       "      <td>악세사리, 쇼핑,라탄,원데이클래스,관광기념품,상점/상가, 쇼핑,라탄,원데이클래스,카...</td>\n",
       "      <td>CNTS_200000000007334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>몸냥공작소</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>귀엽고 제주스러운 유니크한 소품가게</td>\n",
       "      <td>제주특별자치도 제주시 애월읍 유수암리 2503-1</td>\n",
       "      <td>제주특별자치도 제주시 애월읍 하소로 595</td>\n",
       "      <td>33.430614</td>\n",
       "      <td>126.397470</td>\n",
       "      <td>--</td>\n",
       "      <td>https://api.cdn.visitjeju.net/photomng/imgpath...</td>\n",
       "      <td>공방,기념품,,아주 어려움, 공방,기념품,쇼핑,관광기념품,상점/상가</td>\n",
       "      <td>CNTS_000000000022837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>은인마켙</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>자개, 유리 등 다양한 식기류를 만나볼 수 있는 소품샵</td>\n",
       "      <td>제주특별자치도 제주시 조천읍 함덕리 1082</td>\n",
       "      <td>제주특별자치도 제주시 조천읍 함덕서2길 20</td>\n",
       "      <td>33.540661</td>\n",
       "      <td>126.663099</td>\n",
       "      <td>010-3006-7721</td>\n",
       "      <td>https://api.cdn.visitjeju.net/photomng/imgpath...</td>\n",
       "      <td>소품샵, 함덕, 잡화, 식기</td>\n",
       "      <td>CNTS_200000000015021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>뱅뱅와인마켓</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>공항 인근에 위치한 대형 와인판매점</td>\n",
       "      <td>제주특별자치도 제주시 오라이동 2171-1</td>\n",
       "      <td>제주특별자치도 제주시 사평2길 9</td>\n",
       "      <td>33.492220</td>\n",
       "      <td>126.510559</td>\n",
       "      <td>064-746-4141</td>\n",
       "      <td>https://api.cdn.visitjeju.net/photomng/imgpath...</td>\n",
       "      <td>샴페인, 오라동, 와인, 제주시내</td>\n",
       "      <td>CNTS_200000000014989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    title category                                       introduction  \\\n",
       "0      미유       쇼핑                                  숲속 별장처럼 꾸며진 소품 가게   \n",
       "1    마야블루       쇼핑  마야블루는 제주 시내의 주택가 사이에 작은 간판으로 자신의 존재를 알리고 있다. 이...   \n",
       "2   몸냥공작소       쇼핑                                귀엽고 제주스러운 유니크한 소품가게   \n",
       "3    은인마켙       쇼핑                     자개, 유리 등 다양한 식기류를 만나볼 수 있는 소품샵   \n",
       "4  뱅뱅와인마켓       쇼핑                                공항 인근에 위치한 대형 와인판매점   \n",
       "\n",
       "                       address                roadaddress   latitude  \\\n",
       "0    제주특별자치도 제주시 한림읍 옹포리 326-3  제주특별자치도 제주시 한림읍 한림상로 15-5  33.405636   \n",
       "1      제주특별자치도 제주시 노형동 1052-27       제주특별자치도 제주시 월랑로6길 21  33.489570   \n",
       "2  제주특별자치도 제주시 애월읍 유수암리 2503-1    제주특별자치도 제주시 애월읍 하소로 595  33.430614   \n",
       "3     제주특별자치도 제주시 조천읍 함덕리 1082   제주특별자치도 제주시 조천읍 함덕서2길 20  33.540661   \n",
       "4      제주특별자치도 제주시 오라이동 2171-1         제주특별자치도 제주시 사평2길 9  33.492220   \n",
       "\n",
       "    longitude         phoneno  \\\n",
       "0  126.256762  0507-1349-9322   \n",
       "1  126.478593   010-8515-2470   \n",
       "2  126.397470              --   \n",
       "3  126.663099   010-3006-7721   \n",
       "4  126.510559    064-746-4141   \n",
       "\n",
       "                                             imgpath  \\\n",
       "0  https://api.cdn.visitjeju.net/photomng/imgpath...   \n",
       "1  https://api.cdn.visitjeju.net/photomng/imgpath...   \n",
       "2  https://api.cdn.visitjeju.net/photomng/imgpath...   \n",
       "3  https://api.cdn.visitjeju.net/photomng/imgpath...   \n",
       "4  https://api.cdn.visitjeju.net/photomng/imgpath...   \n",
       "\n",
       "                                                 tag            contentsid  \n",
       "0              핸드메이드소품, 키링, 우산, 한림, 옹포리, 소품샵, 지갑, 쇼핑  CNTS_200000000015086  \n",
       "1  악세사리, 쇼핑,라탄,원데이클래스,관광기념품,상점/상가, 쇼핑,라탄,원데이클래스,카...  CNTS_200000000007334  \n",
       "2              공방,기념품,,아주 어려움, 공방,기념품,쇼핑,관광기념품,상점/상가  CNTS_000000000022837  \n",
       "3                                    소품샵, 함덕, 잡화, 식기  CNTS_200000000015021  \n",
       "4                                 샴페인, 오라동, 와인, 제주시내  CNTS_200000000014989  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "\n",
    "# 여기서 이용할 컬럼은 contentsid 하나."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           0\n",
       "category        0\n",
       "introduction    0\n",
       "address         0\n",
       "roadaddress     0\n",
       "latitude        0\n",
       "longitude       0\n",
       "phoneno         0\n",
       "imgpath         2\n",
       "tag             0\n",
       "contentsid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contentsid를 이용해 검색하여 해당 이름을 불러올 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNTS_200000000015086'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cocntentsid = df[['title','contentsid']]\n",
    "df_cocntentsid['contentsid'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미유'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cocntentsid['title'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> contentsid를 통해 검색을 할것. 그러나 title이 뭔지는 알아야하니깐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 검색할 항목 정리\n",
    "- https://www.visitjeju.net/kr/detail/view?contentsid=\n",
    "- df_contentsid['contentsid'][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어떻게 추가할까?\n",
    "- df_contentsid 데이터프레임에 새로운 컬럼을 만들어 붙디던가,\n",
    "- 새로운 데이터 프레임을 만들어 크롤링한 데이터를 저장하고 df_contentsid랑 합치던가.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNTS_000000000019679'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cocntentsid['contentsid'][2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링 할 데이터 정리\n",
    "- class \"inner_wrap\" 데이터(상단 데이터) - 상단 이미지 데이터의 경우 이미 있는 imgPath와 동일하기 때문에 필요 없음.\n",
    "    - title \"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[1]/h3\"\n",
    "    - 별점 \"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[3]/p\"\n",
    "    - mainTag(해당 관광지를 분류 가능) \n",
    "    \"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[1]\"\n",
    "        //*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[1]/a[1]\n",
    "        //*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[1]/a[2]\n",
    "        //*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[1]/a[3]\n",
    "    - subTag(해당 관광지를 조금더 디테일하게 설명 )\n",
    "    \"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[2]\"\n",
    "        //*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[2]/a[1]\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        //*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[2]/a[7]\n",
    "\n",
    "- class \"add2020_detail_left\" 데이터(본문내용 좌측데이터 = 상세정보)\n",
    "    - image 규칙이 없음. 있긴한데 div[3]에는 text가 있고 1,2,4,5에는 이미지가 있고, \n",
    "        - //*[@id=\"tab0\"]/div/div[1]/div[1]/div/div/div/div/img\n",
    "        - //*[@id=\"tab0\"]/div/div[1]/div[2]/div/div/div/div[1]/img\n",
    "        - //*[@id=\"tab0\"]/div/div[1]/div[2]/div/div/div/div[2]/img\n",
    "        - //*[@id=\"tab0\"]/div/div[1]/div[4]/div/div/div/div/img\n",
    "        - //*[@id=\"tab0\"]/div/div[1]/div[5]/div/div/div/div/img\n",
    "    - text\n",
    "        - 와 텍스트가 html언어네 이거 어케 긁어오지? 한번에 긁어올 수 있는 방법 필요.\n",
    "        //*[@id=\"tab0\"]/div/div[1]/div[3]/div/div/div\n",
    "\n",
    "- class \"add2020_detail_right\" 중 이용안내 파트만 긁어오기. 왜냐하면 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롬 켜기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome Browser 와 Chrome Driver Version 확인하기\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service = Service(ChromeDriverManager().install()),options = chrome_options)\n",
    "driver.get(f\"https://www.visitjeju.net/kr/detail/view?contentsid={df_cocntentsid['contentsid'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 수집 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 연습코드\n",
    "# import requests\n",
    "# from lxml import html\n",
    "\n",
    "# # 크롤링할 웹페이지 URL 설정\n",
    "# url = 'https://www.visitjeju.net/kr/detail/view?contentsid=CNTS_000000000019279'\n",
    "# driver.get(url)\n",
    "# scrapy_data = pd.DataFrame(columns=['text1', 'image1'])\n",
    "\n",
    "# text1 = []\n",
    "# image1 = []\n",
    "\n",
    "\n",
    "\n",
    "# try:\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "#     dl_tag = soup.find('dl')\n",
    "#     # 텍스트 가져오기\n",
    "#     text_element = soup.find('div', class_='wrap_contView')\n",
    "#     text = text_element.get_text(strip=True)\n",
    "    \n",
    "#     # 이미지 가져오기\n",
    "#     image_element = soup.find('div', class_='swiper-slide')\n",
    "#     image_url = image_element.find('img')['src']\n",
    "    \n",
    "#     # 데이터프레임에 저장\n",
    "#     data = {'text1': [text], 'image1': [image_url]}\n",
    "#     scrapy_data = pd.DataFrame(data)\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# # 크롤링할 웹페이지 URL 설정\n",
    "# url = 'https://www.visitjeju.net/kr/detail/view?contentsid=CNTS_000000000019279'\n",
    "\n",
    "# # 웹페이지에 GET 요청 보내고 HTML 가져오기\n",
    "# response = requests.get(url)\n",
    "# html = response.text\n",
    "\n",
    "# try:\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "#     # dl 태그 찾기\n",
    "#     dl_tag = soup.find('dl')\n",
    "    \n",
    "#     if dl_tag:\n",
    "#         # 텍스트와 이미지를 저장할 변수 초기화\n",
    "#         text1 = \"\"\n",
    "#         image1 = None\n",
    "        \n",
    "#         # dt와 dd 태그를 모두 찾아서 반복문으로 순회\n",
    "#         for dt_tag, dd_tag in zip(dl_tag.find_all('dt'), dl_tag.find_all('dd')):\n",
    "#             # dt 태그의 텍스트 추출 (제목)\n",
    "#             dt_text = dt_tag.get_text(strip=True)\n",
    "#             # dd 태그의 텍스트 추출 (상세 내용)\n",
    "#             dd_text = dd_tag.get_text(strip=True)\n",
    "            \n",
    "#             # 상세 내용에 이미지가 있는지 확인\n",
    "#             img_tag = dd_tag.find('img')\n",
    "#             if img_tag:\n",
    "#                 # 이미지의 src 속성 값 추출\n",
    "#                 image1 = img_tag.get('src')\n",
    "            \n",
    "#             # dt 태그의 텍스트와 dd 태그의 텍스트를 합쳐서 저장\n",
    "#             if dt_text:\n",
    "#                 text1 += f\"{dt_text}: {dd_text}\\n\"\n",
    "        \n",
    "#         # 데이터프레임에 저장\n",
    "#         data = {'text1': [text1], 'image1': [image1]}\n",
    "#         scrapy_data = pd.DataFrame(data)\n",
    "#     else:\n",
    "#         print(\"dl 태그를 찾을 수 없습니다.\")\n",
    "# except Exception as e:\n",
    "#     print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 크롤링할 웹페이지 URL 설정\n",
    "# url = 'https://www.visitjeju.net/kr/detail/view?contentsid=CNTS_000000000019279'\n",
    "# driver.get(url)\n",
    "\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "# # # dl 태그 찾기\n",
    "# # XPath로 dl 태그 찾기\n",
    "# dl_element = driver.find_element(By.XPATH,\"/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div[2]/div[2]/div\")\n",
    "# try:\n",
    "#     # dt = title\n",
    "#     dt_elements = dl_element.find_elements(By.TAG_NAME, \"dt\")\n",
    "#     # dd = detail\n",
    "#     dd_elements = dl_element.find_elements(By.TAG_NAME, \"dd\")\n",
    "\n",
    "#     for dt, dd in zip(dt_elements, dd_elements):\n",
    "#         print(f\"{dt.text}-{dd.text}\")\n",
    "    \n",
    "\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "#     print('크롤링 실패')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd_elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*[@id=\"content\"]/div[2]/div[2]/div[2]/div[2]/div[2]/div\n",
    "# //*[@id=\"content\"]/div[2]/div[2]/div[2]/div[2]/div[2]/div/dl/dt[1] #소개\n",
    "# //*[@id=\"content\"]/div[2]/div[2]/div[2]/div[2]/div[2]/div/dl/dd[1]/text() #관광지와 가까운 마니주펜션\n",
    "# //*[@id=\"content\"]/div[2]/div[2]/div[2]/div[2]/div[2]/div/dl/dt[2] #이용시간\n",
    "# //*[@id=\"content\"]/div[2]/div[2]/div[2]/div[2]/div[2]/div/dl/dd[2]/text()\n",
    "\n",
    "# //*[@id=\"content\"]/div[2]/div[2]/div[2]/div[2]/div[2]/div/dl/dd[3] #공용주차장..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 크롤링할 웹페이지 URL 설정\n",
    "# url = 'https://www.visitjeju.net/kr/detail/view?contentsid=CNTS_000000000019279'\n",
    "# driver.get(url)\n",
    "\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "# # # dl 태그 찾기\n",
    "# # XPath로 dl 태그 찾기\n",
    "# # test_element = driver.find_element(By.XPATH, \"/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div[2]/div[2]\")\n",
    "# dl_element = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div[2]/div[2]/div')\n",
    "# try:\n",
    "#     # dt = title\n",
    "#     dt_elements_save = []\n",
    "#     # dt_elements = dl_element.find_elements(By.TAG_NAME, \"//dl/dt\")\n",
    "#     dt_elements = dl_element.find_elements(By.XPATH, \"/dl/dt\")\n",
    "#     # dd = detail\n",
    "#     dd_elements_save = []\n",
    "#     dd_elements = dl_element.find_elements(By.XPATH, \"/dl/dd\")\n",
    "\n",
    "#     for idx, dt, dd in zip(dt_elements, dd_elements):\n",
    "#         idx + 1\n",
    "#         dt_elements_save.append(dt[idx])\n",
    "#         dd_elements_save.append(dd[idx])\n",
    "#         print(f\"{dt.text}-{dd.text}\")\n",
    "    \n",
    "\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "#     print('크롤링 실패')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# body Left 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Link: https://api.cdn.visitjeju.net/photomng/imgpath/202306/13/34c0934e-f750-49db-9a3a-7382581d8924.jpg\n",
      "Image Link: https://api.cdn.visitjeju.net/photomng/imgpath/202306/13/05c35d7a-6be0-4e81-b93f-1919dce0b077.jpg\n",
      "Image Link: https://api.cdn.visitjeju.net/photomng/imgpath/202306/13/90e8ed4a-91ae-4506-81ac-f67914d0fc63.jpg\n",
      "Image Link: https://api.cdn.visitjeju.net/photomng/imgpath/202306/13/e97ea3a8-790a-4041-9953-c06f1f19ec29.jpg\n",
      "Image Link: https://api.cdn.visitjeju.net/photomng/imgpath/202306/13/4f0a2f93-6e0a-47ca-a710-6ab9ff1168b1.jpg\n",
      "Image Link: https://api.cdn.visitjeju.net/photomng/imgpath/202306/13/0c7e5875-c0d5-4f63-96b6-0176dd4ce854.jpg\n",
      "Text: 가게 규모가 크진 않지만, 제주 여행 기념품 종류를 다양하게 구비하고 있어 둘러보는 재미가 쏠쏠한 편. 귤 모양 파우치, 스트링 백과 같은 사장님이 직접 만든 핸드메이드 제품도 선보인다. 여행객에게 인기 아이템인 모자의 경우 털, 뜨개실, 면 등 여러 소재가 구비되어 취향껏 고르기에 좋으며, 우산, 선글라스, 지갑, 키링과 같은 잡화류도 다양한 디자인이 준비되어 있다.\n",
      "Text: 미유는 일몰의 풍경이 아름다운 것으로 유명한 한림항 인근에 있는 소품 가게이다. 멀리서도 눈에 띄는 나무건물은 빈티지한 분위기를 자아낸다. 노란색 간판에 가게의 상호가 쓰여 있다. 입구를 열고 들어서면 마치 별장처럼 꾸며진 공간이 눈길을 끈다. 인테리어는 전체적으로 나무를 활용하여 인위적이지 않고 자연스러운 느낌이다.\n",
      "Text: 이뿐 아니라 제주 특산물로 만든 다양한 먹거리들도 구비돼 있다. 스테디셀러인 초콜릿이나 과즐, 타르트 등은 선물용으로 인기가 좋다. 진열이 깔끔하게 돼 있고, 상품의 가짓수가 많아 둘러보는 재미가 쏠쏠하다.  제주여행 기념품 쇼핑을 하고 싶을 때 방문할 만한 곳이다.\n",
      "Text: 숲속 별장처럼 꾸며진 소품 가게\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 요소들을 가져올 XPath\n",
    "xpath = '/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div[1]/div[1]/div/div[1]//*'\n",
    "\n",
    "# 이미지와 텍스트를 모두 가져오는 함수\n",
    "def get_images_and_texts(driver, xpath):\n",
    "    elements = driver.find_elements(By.XPATH, xpath)\n",
    "    images = []\n",
    "    texts = []\n",
    "\n",
    "    for element in elements:\n",
    "        if element.tag_name == 'img':\n",
    "            images.append(element.get_attribute('src'))\n",
    "        else:\n",
    "            # p 태그 안에 있는 text만 가져오기\n",
    "            p_elements = element.find_elements(By.XPATH, './/p')\n",
    "            for p_element in p_elements:\n",
    "                text = p_element.text.strip()\n",
    "                if text:\n",
    "                    texts.append(text)\n",
    "    # 중복된 항목 제거\n",
    "    unique_texts = list(set(texts))\n",
    "    return images, unique_texts\n",
    "\n",
    "# 이미지와 텍스트 가져오기\n",
    "images, texts = get_images_and_texts(driver, xpath)\n",
    "\n",
    "# 결과 출력\n",
    "for image in images:\n",
    "    print(\"Image Link:\", image)\n",
    "\n",
    "for text in texts:\n",
    "    print(\"Text:\", text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 본 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome Browser 와 Chrome Driver Version 확인하기\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service = Service(ChromeDriverManager().install()),options = chrome_options)\n",
    "driver.get(f\"https://www.visitjeju.net/kr/detail/view?contentsid={df_cocntentsid['contentsid'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================현재 page : 0, title : 미유====================\n",
      "추천 버튼이 없습니다.\n",
      "미유 - 별점(별점없음)\n",
      "#한림, #옹포리, #소품샵\n",
      "#핸드메이드소품,#키링,#우산,#지갑,#쇼핑\n",
      "0BodyLeftImage: https://api.cdn.visitjeju.net/photomng/imgpath/202306/13/34c0934e-f750-49db-9a3a-7382581d8924.jpg\n",
      "1BodyLeftImage: https://api.cdn.visitjeju.net/photomng/imgpath/202306/13/05c35d7a-6be0-4e81-b93f-1919dce0b077.jpg\n",
      "2BodyLeftImage: https://api.cdn.visitjeju.net/photomng/imgpath/202306/13/90e8ed4a-91ae-4506-81ac-f67914d0fc63.jpg\n",
      "3BodyLeftImage: https://api.cdn.visitjeju.net/photomng/imgpath/202306/13/e97ea3a8-790a-4041-9953-c06f1f19ec29.jpg\n",
      "4BodyLeftImage: https://api.cdn.visitjeju.net/photomng/imgpath/202306/13/4f0a2f93-6e0a-47ca-a710-6ab9ff1168b1.jpg\n",
      "5BodyLeftImage: https://api.cdn.visitjeju.net/photomng/imgpath/202306/13/0c7e5875-c0d5-4f63-96b6-0176dd4ce854.jpg\n",
      "0BodyLeftText: 가게 규모가 크진 않지만, 제주 여행 기념품 종류를 다양하게 구비하고 있어 둘러보는 재미가 쏠쏠한 편. 귤 모양 파우치, 스트링 백과 같은 사장님이 직접 만든 핸드메이드 제품도 선보인다. 여행객에게 인기 아이템인 모자의 경우 털, 뜨개실, 면 등 여러 소재가 구비되어 취향껏 고르기에 좋으며, 우산, 선글라스, 지갑, 키링과 같은 잡화류도 다양한 디자인이 준비되어 있다.\n",
      "1BodyLeftText: 이뿐 아니라 제주 특산물로 만든 다양한 먹거리들도 구비돼 있다. 스테디셀러인 초콜릿이나 과즐, 타르트 등은 선물용으로 인기가 좋다. 진열이 깔끔하게 돼 있고, 상품의 가짓수가 많아 둘러보는 재미가 쏠쏠하다.  제주여행 기념품 쇼핑을 하고 싶을 때 방문할 만한 곳이다.\n",
      "2BodyLeftText: 미유는 일몰의 풍경이 아름다운 것으로 유명한 한림항 인근에 있는 소품 가게이다. 멀리서도 눈에 띄는 나무건물은 빈티지한 분위기를 자아낸다. 노란색 간판에 가게의 상호가 쓰여 있다. 입구를 열고 들어서면 마치 별장처럼 꾸며진 공간이 눈길을 끈다. 인테리어는 전체적으로 나무를 활용하여 인위적이지 않고 자연스러운 느낌이다.\n",
      "3BodyLeftText: 숲속 별장처럼 꾸며진 소품 가게\n",
      "bodyRightText : 소개-숲속 별장처럼 꾸며진 소품 가게\n",
      "bodyRightText : 이용 시간-평일 : 11:00 ~ 18:00 , 주말 : 11:00 ~ 18:00\n",
      "=================현재 page : 1, title : 마야블루====================\n",
      "추천 버튼이 없습니다.\n",
      "마야블루 - 별점(별점없음)\n",
      "#쇼핑, #라탄, #원데이클래스\n",
      "#관광기념품,#상점/상가\n",
      "0BodyLeftImage: https://api.cdn.visitjeju.net/photomng/imgpath/201808/07/79973b06-a126-4a79-a42e-6ccef9d67e0a.jpg\n",
      "1BodyLeftImage: https://api.cdn.visitjeju.net/photomng/imgpath/201808/07/530ff960-3d02-42b6-89ff-7d19f7232dae.jpg\n",
      "2BodyLeftImage: https://api.cdn.visitjeju.net/photomng/imgpath/201808/07/a89fddd8-ab61-4fa4-a057-abfdeeb61e84.jpg\n",
      "3BodyLeftImage: https://api.cdn.visitjeju.net/photomng/imgpath/201808/07/83a74b96-5606-4178-a099-9d68f84ea239.jpg\n",
      "4BodyLeftImage: https://api.cdn.visitjeju.net/photomng/imgpath/201808/07/3f3d76e3-5bb9-4d2d-b7a0-a22246370f15.jpg\n",
      "5BodyLeftImage: https://api.cdn.visitjeju.net/photomng/imgpath/201808/07/35ae1dc3-0e8b-42a1-b974-af9debb88fda.jpg\n",
      "0BodyLeftText: 제주에는 작지만 매력적인 공간들이 꽤나 많다. 마야블루는 제주 시내의 주택가 사이에 작은 간판으로 자신의 존재를 알리고 있다. 이곳은 소품 판매와 함께 공방을 운영하면서 드림캐처와 캔들 등 직접 만들어 볼 수 있는 원데이 클래스도 진행하고 있다. 그렇기에 이미 라탄을 좋아하는 단골 손님이 많은 소품샵이기도 하다. 마야블루는 주로 태국에서 주인장이 구매해 온 소품들이 많다. 해외에서 직접 사 온 물건들도 있고, 주인장이 한 땀 한 땀 정성 들여 만든 핸드메이드 물건도 있는 곳이다.\n",
      "\n",
      "주로 태국에서 물건을 들여오는 소품샵이기 때문에, 공식 휴일 이외에도 문을 열지 않는 경우가 있다. 물건을 구하러 다녀오는 기간에는 영업을 하지 않으니, 공식 SNS를 통해 영업 여부 확인 후 방문하는 것을 추천한다. 전체적으로 가격이 비싸지 않은 편이며, 라탄 바구니와 가방은 2만 원 선부터 시작하니 참고하자.\n",
      "1BodyLeftText: 마야블루\n",
      "bodyRightText : 소개-마야블루는 제주 시내의 주택가 사이에 작은 간판으로 자신의 존재를 알리고 있다. 이곳은 소품 판매와 함께 공방을 운영하면서 드림캐처와 캔들 등 직접 만들어 볼 수 있는 원데이 클래스도 진행하고 있다\n",
      "bodyRightText : 상세 정보-일요일 휴무\n",
      "bodyRightText : 이용 시간-평일 : 10:00 ~ 19:00 , 주말 : 10:00 ~ 19:00\n",
      "bodyRightText : 취급품목 기타-드림캐처, 캔들, 악세사리, 라탄 소품\n",
      "bodyRightText : 편의시설-카드결제,현금결제\n"
     ]
    }
   ],
   "source": [
    "# 본 코드\n",
    "mainUrl= \"https://www.visitjeju.net/kr/detail/view?contentsid=\"\n",
    "contentsid = df_cocntentsid['contentsid']\n",
    "# 크롤링 설정\n",
    "idx = 0 # 크롤링할 데이터 총 갯수\n",
    "failed_idx = 0 # 크롤링 실패시 1 증가\n",
    "\n",
    "t = random.randrange(1,2)\n",
    "\n",
    "# 크롤링할 데이터 담길 곳(header, body_left, body_right)\n",
    "    # header (title, stars, mainTag, subTag)\n",
    "scrapy_header = pd.DataFrame(columns=['title', 'stars', 'mainTag', 'subTag'])\n",
    "    # body_left를 image, text로 나눔 image는 개발자 사용, text는 분석가 사용\n",
    "scrapy_left_image = pd.DataFrame(columns=['title', 'image'])\n",
    "scrapy_left_text = pd.DataFrame(columns=['title', 'text'])\n",
    "    # body_right (subInformTitle == dt, subInformText == dd)\n",
    "scrapy_right_개발 = pd.DataFrame(columns=['title','BodyRightText'])\n",
    "scrapy_right_분석 = pd.DataFrame(columns=['title', 'BodyRightText'])\n",
    "\n",
    "\n",
    "# 본문 크롤링\n",
    "for index, contentName in enumerate(contentsid[0:2]):\n",
    "    print(f\"=================현재 page : {index}, title : {df_cocntentsid['title'][index]}====================\")\n",
    "    time.sleep(t)\n",
    "    driver.get(f\"{mainUrl}{contentsid[index]}\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 추천 버튼 뜨면 클릭\n",
    "    try:\n",
    "        # 추천 버튼이 있는지 확인\n",
    "        recommend_button = driver.find_element(By.XPATH, '//*[@id=\"footer\"]/div[4]/button')\n",
    "        \n",
    "        # 추천 버튼이 있을 경우 클릭\n",
    "        if recommend_button.is_displayed():\n",
    "            recommend_button.click()\n",
    "            print(\"===================버튼클릭완료 ===================\")\n",
    "            time.sleep(t)\n",
    "    except Exception as e:\n",
    "        print(\"추천 버튼이 없습니다.\")\n",
    "\n",
    "    \n",
    "    # ========================header 크롤링=======================\n",
    "    # title, stars, mainTag, subTag\n",
    "    headerSelector = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[1]/div[1]')\n",
    "    try:\n",
    "        header_title = headerSelector.find_elements(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[1]/h3')\n",
    "        header_stars = headerSelector.find_elements(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[3]/p')\n",
    "        header_mainTag = headerSelector.find_elements(By.CLASS_NAME, \"best_tag\")\n",
    "        header_subTag = headerSelector.find_elements(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[2]')\n",
    "        # title, stars\n",
    "        for h_title, h_stars in zip(header_title, header_stars):\n",
    "            print(h_title.text,\"-\", h_stars.text)\n",
    "            # scrapy_header[['title']] = pd.concat({'title': h_title.text},ignore_index=True)\n",
    "            # scrapy_header[['stars']] = pd.concat({'stars': h_stars.text},ignore_index=True)\n",
    "\n",
    "        # mainTag\n",
    "        for midx, h_mainTag in enumerate(header_mainTag):\n",
    "            # 태그 분리\n",
    "            tags = h_mainTag.text.split(\"#\")\n",
    "            tags = [f\"#{tag.strip()}\" for tag in tags if tag.strip()]  # \"#\"을 다시 추가하여 태그 리스트 작성\n",
    "            print(\", \".join(tags))  # 분리된 태그들을 출력        \n",
    "            # scrapy_header[['mainTag']] = pd.concat({'mainTag': \", \".join(tags)},ignore_index=True)\n",
    "            \n",
    "        # subTag\n",
    "        for midx, h_subTag in enumerate(header_subTag):\n",
    "            stags = h_subTag.find_elements(By.TAG_NAME, 'a')\n",
    "            ###안되면 아래두줄 살리기\n",
    "            # for stag in stags:\n",
    "            #     print(f\"sub태그{index} : {stag.text}\")\n",
    "            stags = h_subTag.text.split(\"#\")\n",
    "            stags = [f\"#{stag.strip()}\" for stag in stags if stag.strip()]\n",
    "            print(\",\".join(stags))\n",
    "            # scrapy_header[['subTag']] = pd.concat({'subTag': \", \".join(stags)},ignore_index=True)\n",
    "        \n",
    "        # 헤더 데이터 저장\n",
    "        for h_title, h_stars, h_mainTag, h_subTag in zip(header_title, header_stars, header_mainTag, header_subTag):\n",
    "            scrapy_header.loc[len(scrapy_header)] = [h_title.text, h_stars.text, h_mainTag.text if h_mainTag else None, h_subTag.text if h_subTag else None]\n",
    "            \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"헤더 크롤링 실패\")\n",
    "        continue\n",
    "    \n",
    "    time.sleep(t)\n",
    "    # ========================bodyLeft크롤링=======================\n",
    "    # bodyLeftText, bodyLeftImage\n",
    "        # image 링크 예시\n",
    "        # api.cdn.visitjeju.net/photomng/imgpath/202306/15/05dc24f9-60b7-415b-bf27-57361e59147d.jpg\n",
    "    bodyLeftSelector = '/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div[1]/div[1]/div/div[1]//*'\n",
    "    bodyLeftImages = []\n",
    "    bodyLeftTexts = []\n",
    "    # 이미지와 텍스트를 모두 가져오는 함수\n",
    "    def get_images_and_texts(driver, bodyLeftSelector):\n",
    "        elements = driver.find_elements(By.XPATH, bodyLeftSelector)\n",
    "\n",
    "        for element in elements:\n",
    "            if element.tag_name == 'img':\n",
    "                bodyLeftImages.append(element.get_attribute('src'))\n",
    "            else:\n",
    "                # p 태그 안에 있는 text만 가져오기\n",
    "                p_elements = element.find_elements(By.XPATH, './/p')\n",
    "                for p_element in p_elements:\n",
    "                    text = p_element.text.strip()\n",
    "                    if text:\n",
    "                        bodyLeftTexts.append(text)\n",
    "        # 중복된 항목 제거\n",
    "        unique_texts = list(set(bodyLeftTexts))\n",
    "        return bodyLeftImages, unique_texts\n",
    "\n",
    "    # 이미지와 텍스트 가져오기\n",
    "    try:\n",
    "        bodyLeftImages, unique_texts = get_images_and_texts(driver, bodyLeftSelector)\n",
    "        # 결과 출력\n",
    "        for idx, image in enumerate(bodyLeftImages):\n",
    "            print(f\"{idx}BodyLeftImage:\", image)\n",
    "            # scrapy_left_image에 이미지 추가\n",
    "            scrapy_left_image.loc[len(scrapy_left_image)] = [f\"{h_title.text}{idx}\", image]\n",
    "            \n",
    "\n",
    "        for idx, text in enumerate(unique_texts):\n",
    "            print(f\"{idx}BodyLeftText:\", text)\n",
    "            # scrapy_left_text.loc[len(scrapy_left_text)] = [h_title.text, text]\n",
    "        combined_text = ' '.join(unique_texts)  # 모든 텍스트를 공백으로 구분하여 하나의 문자열로 합침\n",
    "        scrapy_left_text.loc[len(scrapy_left_text)] = [h_title.text, combined_text]  # 한 행으로 추가\n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"bodyLeft크롤링 실패\")\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    # ========================bodyRight 크롤링=======================\n",
    "    # dl 태그 찾기\n",
    "    dl_element = driver.find_element(By.XPATH,\"/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div[2]/div[2]/div\")\n",
    "    try:\n",
    "        # dt = title\n",
    "        dt_elements = dl_element.find_elements(By.TAG_NAME, \"dt\")\n",
    "        # dd = detail\n",
    "        dd_elements = dl_element.find_elements(By.TAG_NAME, \"dd\")\n",
    "        time.sleep(1)\n",
    "        # dt_elements와 dd_elements의 text 출력\n",
    "        for dt, dd in zip(dt_elements, dd_elements):\n",
    "            print(f'bodyRightText : {dt.text}-{dd.text}')\n",
    "            scrapy_right_개발.loc[len(scrapy_right_개발)] = [f\"{h_title.text}\",f\"{dt.text}-{dd.text}\"]\n",
    "            scrapy_right_분석 = scrapy_right_개발.groupby('title')['BodyRightText'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "            scrapy_right_분석 = scrapy_right_분석.set_index('title').reindex(scrapy_header['title']).reset_index()\n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('bodyRight크롤링 실패')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>BodyRightText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미유</td>\n",
       "      <td>소개-숲속 별장처럼 꾸며진 소품 가게</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>미유</td>\n",
       "      <td>이용 시간-평일 : 11:00 ~ 18:00 , 주말 : 11:00 ~ 18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>마야블루</td>\n",
       "      <td>소개-마야블루는 제주 시내의 주택가 사이에 작은 간판으로 자신의 존재를 알리고 있다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>마야블루</td>\n",
       "      <td>상세 정보-일요일 휴무</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>마야블루</td>\n",
       "      <td>이용 시간-평일 : 10:00 ~ 19:00 , 주말 : 10:00 ~ 19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>마야블루</td>\n",
       "      <td>취급품목 기타-드림캐처, 캔들, 악세사리, 라탄 소품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>마야블루</td>\n",
       "      <td>편의시설-카드결제,현금결제</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  title                                      BodyRightText\n",
       "0    미유                               소개-숲속 별장처럼 꾸며진 소품 가게\n",
       "1    미유      이용 시간-평일 : 11:00 ~ 18:00 , 주말 : 11:00 ~ 18:00\n",
       "2  마야블루  소개-마야블루는 제주 시내의 주택가 사이에 작은 간판으로 자신의 존재를 알리고 있다...\n",
       "3  마야블루                                       상세 정보-일요일 휴무\n",
       "4  마야블루      이용 시간-평일 : 10:00 ~ 19:00 , 주말 : 10:00 ~ 19:00\n",
       "5  마야블루                      취급품목 기타-드림캐처, 캔들, 악세사리, 라탄 소품\n",
       "6  마야블루                                     편의시설-카드결제,현금결제"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrapy_header\n",
    "scrapy_left_image\n",
    "scrapy_left_text.head()\n",
    "scrapy_right_개발"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>BodyRightText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미유</td>\n",
       "      <td>소개-숲속 별장처럼 꾸며진 소품 가게, 이용 시간-평일 : 11:00 ~ 18:00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>마야블루</td>\n",
       "      <td>소개-마야블루는 제주 시내의 주택가 사이에 작은 간판으로 자신의 존재를 알리고 있다...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  title                                      BodyRightText\n",
       "0    미유  소개-숲속 별장처럼 꾸며진 소품 가게, 이용 시간-평일 : 11:00 ~ 18:00...\n",
       "1  마야블루  소개-마야블루는 제주 시내의 주택가 사이에 작은 간판으로 자신의 존재를 알리고 있다..."
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapy_right_분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>stars</th>\n",
       "      <th>mainTag</th>\n",
       "      <th>subTag</th>\n",
       "      <th>text</th>\n",
       "      <th>BodyRightText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미유</td>\n",
       "      <td>별점(별점없음)</td>\n",
       "      <td>#한림 #옹포리 #소품샵</td>\n",
       "      <td>#핸드메이드소품 #키링 #우산 #지갑 #쇼핑</td>\n",
       "      <td>가게 규모가 크진 않지만, 제주 여행 기념품 종류를 다양하게 구비하고 있어 둘러보는...</td>\n",
       "      <td>소개-숲속 별장처럼 꾸며진 소품 가게, 이용 시간-평일 : 11:00 ~ 18:00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>마야블루</td>\n",
       "      <td>별점(별점없음)</td>\n",
       "      <td>#쇼핑 #라탄 #원데이클래스</td>\n",
       "      <td>#관광기념품 #상점/상가</td>\n",
       "      <td>제주에는 작지만 매력적인 공간들이 꽤나 많다. 마야블루는 제주 시내의 주택가 사이에...</td>\n",
       "      <td>소개-마야블루는 제주 시내의 주택가 사이에 작은 간판으로 자신의 존재를 알리고 있다...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  title     stars          mainTag                    subTag  \\\n",
       "0    미유  별점(별점없음)    #한림 #옹포리 #소품샵  #핸드메이드소품 #키링 #우산 #지갑 #쇼핑   \n",
       "1  마야블루  별점(별점없음)  #쇼핑 #라탄 #원데이클래스             #관광기념품 #상점/상가   \n",
       "\n",
       "                                                text  \\\n",
       "0  가게 규모가 크진 않지만, 제주 여행 기념품 종류를 다양하게 구비하고 있어 둘러보는...   \n",
       "1  제주에는 작지만 매력적인 공간들이 꽤나 많다. 마야블루는 제주 시내의 주택가 사이에...   \n",
       "\n",
       "                                       BodyRightText  \n",
       "0  소개-숲속 별장처럼 꾸며진 소품 가게, 이용 시간-평일 : 11:00 ~ 18:00...  \n",
       "1  소개-마야블루는 제주 시내의 주택가 사이에 작은 간판으로 자신의 존재를 알리고 있다...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 합치기\n",
    "# scrapy_header와 scrapy_left_text 병합\n",
    "scrapy_combined_data = pd.merge(scrapy_header, scrapy_left_text, on='title', how='inner')\n",
    "scrapy_combined_data = pd.merge(scrapy_combined_data, scrapy_right_분석, on='title', how='inner')\n",
    "scrapy_combined_data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "scrapy_combined_data.to_csv(\"Data/visitJeju 크롤링.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 백업 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 본 코드\n",
    "# mainUrl= \"https://www.visitjeju.net/kr/detail/view?contentsid=\"\n",
    "# contentsid = df_cocntentsid['contentsid']\n",
    "# # 크롤링 설정\n",
    "# idx = 0 # 크롤링할 데이터 총 갯수\n",
    "# failed_idx = 0 # 크롤링 실패시 1 증가\n",
    "\n",
    "# t = random.randrange(1,2)\n",
    "\n",
    "# # 크롤링할 데이터 담길 곳(header, body_left, body_right)\n",
    "#     # header (title, stars, mainTag, subTag)\n",
    "# scrapy_header = pd.DataFrame(columns=['title', 'stars', 'mainTag', 'subTag'])\n",
    "#     # body_left (additional_image, mainText)\n",
    "# scrapy_left = pd.DataFrame(columns=['BodyLeftImage', 'BodyLeftText'])\n",
    "#     # body_right (subInformTitle == dt, subInformText == dd)\n",
    "# scrapy_right = pd.DataFrame(columns=['BodyRightText'])\n",
    "\n",
    "\n",
    "# # 본문 크롤링\n",
    "# for index, contentName in enumerate(contentsid[0:5]):\n",
    "#     current_data = {}\n",
    "#     current_data['page'] = index\n",
    "#     current_data['title'] = df_cocntentsid['title'][index]\n",
    "    \n",
    "#     print(f\"=================현재 page : {index}, title : {df_cocntentsid['title'][index]}====================\")\n",
    "#     time.sleep(t)\n",
    "#     driver.get(f\"{mainUrl}{contentsid[index]}\")\n",
    "#     html = driver.page_source\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#     # 추천 버튼 뜨면 클릭\n",
    "#     try:\n",
    "#         # 추천 버튼이 있는지 확인\n",
    "#         recommend_button = driver.find_element(By.XPATH, '//*[@id=\"footer\"]/div[4]/button')\n",
    "        \n",
    "#         # 추천 버튼이 있을 경우 클릭\n",
    "#         if recommend_button.is_displayed():\n",
    "#             recommend_button.click()\n",
    "#             print(\"===================버튼클릭완료 ===================\")\n",
    "#             time.sleep(t)\n",
    "#     except Exception as e:\n",
    "#         print(\"추천 버튼이 없습니다.\")\n",
    "\n",
    "    \n",
    "#     # ========================header 크롤링=======================\n",
    "#     # title, stars, mainTag, subTag\n",
    "#     headerSelector = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[1]/div[1]')\n",
    "#     try:\n",
    "#         headerData_title = []\n",
    "#         headerData_stars = []\n",
    "#         headerData_mainTag = []\n",
    "#         headerData_subTag = []\n",
    "\n",
    "#         header_title = headerSelector.find_elements(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[1]/h3')\n",
    "#         header_stars = headerSelector.find_elements(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[3]/p')\n",
    "#         header_mainTag = headerSelector.find_elements(By.CLASS_NAME, \"best_tag\")\n",
    "#         # header_subTag = headerSelector.find_elements(By.XPATH, '//p[@data-v-51160e04]')\n",
    "#         header_subTag = headerSelector.find_elements(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[2]')\n",
    "#         # title, stars\n",
    "#         for h_title, h_stars in zip(header_title, header_stars):\n",
    "#             print(h_title.text,\"-\", h_stars.text)\n",
    "#             # headerData_title.append(h_title.text)\n",
    "#             # headerData_stars.append(h_stars.text)\n",
    "\n",
    "#         # mainTag\n",
    "#         for midx, h_mainTag in enumerate(header_mainTag):\n",
    "#             # 태그 분리\n",
    "#             tags = h_mainTag.text.split(\"#\")\n",
    "#             tags = [f\"main태그{index}: #{tag.strip()}\" for tag in tags if tag.strip()]  # \"#\"을 다시 추가하여 태그 리스트 작성\n",
    "#             print(\", \".join(tags))  # 분리된 태그들을 출력\n",
    "#             # headerData_mainTag.append(tags)\n",
    "#         # subTag\n",
    "#         for midx, h_subTag in enumerate(header_subTag):\n",
    "#             stags = h_subTag.find_elements(By.TAG_NAME, 'a')\n",
    "#             for stag in stags:\n",
    "#                 print(f\"sub태그{index} : {stag.text}\")\n",
    "#                 # sub_tags.append(stag.text)\n",
    "#             # headerData_subTag.append(sub_tags)\n",
    "        \n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(\"헤더 크롤링 실패\")\n",
    "#         continue\n",
    "    \n",
    "#     time.sleep(t)\n",
    "#     # ========================bodyLeft크롤링=======================\n",
    "#     # bodyLeftText, bodyLeftImage\n",
    "#         # image 링크 예시\n",
    "#         # api.cdn.visitjeju.net/photomng/imgpath/202306/15/05dc24f9-60b7-415b-bf27-57361e59147d.jpg\n",
    "#     bodyLeftSelector = '/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div[1]/div[1]/div/div[1]//*'\n",
    "#     bodyLeftImages = []\n",
    "#     bodyLeftTexts = []\n",
    "#     # 이미지와 텍스트를 모두 가져오는 함수\n",
    "#     def get_images_and_texts(driver, bodyLeftSelector):\n",
    "#         elements = driver.find_elements(By.XPATH, bodyLeftSelector)\n",
    "\n",
    "#         for element in elements:\n",
    "#             if element.tag_name == 'img':\n",
    "#                 bodyLeftImages.append(element.get_attribute('src'))\n",
    "#             else:\n",
    "#                 # p 태그 안에 있는 text만 가져오기\n",
    "#                 p_elements = element.find_elements(By.XPATH, './/p')\n",
    "#                 for p_element in p_elements:\n",
    "#                     text = p_element.text.strip()\n",
    "#                     if text:\n",
    "#                         bodyLeftTexts.append(text)\n",
    "#         # 중복된 항목 제거\n",
    "#         unique_texts = list(set(bodyLeftTexts))\n",
    "#         return bodyLeftImages, unique_texts\n",
    "\n",
    "#     # 이미지와 텍스트 가져오기\n",
    "#     try:\n",
    "#         bodyLeftImages, unique_texts = get_images_and_texts(driver, bodyLeftSelector)\n",
    "#         # 결과 출력\n",
    "#         for idx, image in enumerate(bodyLeftImages):\n",
    "#             print(f\"{idx}BodyLeftImage:\", image)\n",
    "\n",
    "#         for idx, text in enumerate(unique_texts):\n",
    "#             print(f\"{idx}BodyLeftText:\", text)\n",
    "\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(\"bodyLeft크롤링 실패\")\n",
    "#         continue\n",
    "\n",
    "\n",
    "\n",
    "#     # ========================bodyRight 크롤링=======================\n",
    "#     bodyRightData = [] # 상세정보\n",
    "#     # dl 태그 찾기\n",
    "#     dl_element = driver.find_element(By.XPATH,\"/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div[2]/div[2]/div\")\n",
    "#     try:\n",
    "#         # dt = title\n",
    "#         dt_elements = dl_element.find_elements(By.TAG_NAME, \"dt\")\n",
    "#         # dd = detail\n",
    "#         dd_elements = dl_element.find_elements(By.TAG_NAME, \"dd\")\n",
    "#         time.sleep(1)\n",
    "#         # dt_elements와 dd_elements의 text 출력\n",
    "#         for dt, dd in zip(dt_elements, dd_elements):\n",
    "#             print(f'bodyRightText : {dt.text}-{dd.text}')\n",
    "#             bodyRightData.append(f\"{dt.text}-{dd.text}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print('bodyRight크롤링 실패')\n",
    "\n",
    "# # 결과 출력\n",
    "# print(\"Header Data:\")\n",
    "# print(scrapy_header)\n",
    "# print(\"\\nBody Left Data:\")\n",
    "# print(scrapy_left)\n",
    "# print(\"\\nBody Right Data:\")\n",
    "# print(scrapy_right)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
