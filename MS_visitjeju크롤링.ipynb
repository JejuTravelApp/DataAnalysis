{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from urllib.parse import quote\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver  # 동적크롤링\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_scrapy_data : 전처리가 끝난 visitJeju의 API 전체 CSV\n",
    "data = pd.read_csv(\"Data/visit_jeju_scrapy_data.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>introduction</th>\n",
       "      <th>address</th>\n",
       "      <th>roadaddress</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phoneno</th>\n",
       "      <th>imgpath</th>\n",
       "      <th>tag</th>\n",
       "      <th>contentsid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미유</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>숲속 별장처럼 꾸며진 소품 가게</td>\n",
       "      <td>제주특별자치도 제주시 한림읍 옹포리 326-3</td>\n",
       "      <td>제주특별자치도 제주시 한림읍 한림상로 15-5</td>\n",
       "      <td>33.405636</td>\n",
       "      <td>126.256762</td>\n",
       "      <td>0507-1349-9322</td>\n",
       "      <td>https://api.cdn.visitjeju.net/photomng/imgpath...</td>\n",
       "      <td>핸드메이드소품, 키링, 우산, 한림, 옹포리, 소품샵, 지갑, 쇼핑</td>\n",
       "      <td>CNTS_200000000015086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>마야블루</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>마야블루는 제주 시내의 주택가 사이에 작은 간판으로 자신의 존재를 알리고 있다. 이...</td>\n",
       "      <td>제주특별자치도 제주시 노형동 1052-27</td>\n",
       "      <td>제주특별자치도 제주시 월랑로6길 21</td>\n",
       "      <td>33.489570</td>\n",
       "      <td>126.478593</td>\n",
       "      <td>010-8515-2470</td>\n",
       "      <td>https://api.cdn.visitjeju.net/photomng/imgpath...</td>\n",
       "      <td>악세사리, 쇼핑,라탄,원데이클래스,관광기념품,상점/상가, 쇼핑,라탄,원데이클래스,카...</td>\n",
       "      <td>CNTS_200000000007334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>몸냥공작소</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>귀엽고 제주스러운 유니크한 소품가게</td>\n",
       "      <td>제주특별자치도 제주시 애월읍 유수암리 2503-1</td>\n",
       "      <td>제주특별자치도 제주시 애월읍 하소로 595</td>\n",
       "      <td>33.430614</td>\n",
       "      <td>126.397470</td>\n",
       "      <td>--</td>\n",
       "      <td>https://api.cdn.visitjeju.net/photomng/imgpath...</td>\n",
       "      <td>공방,기념품,,아주 어려움, 공방,기념품,쇼핑,관광기념품,상점/상가</td>\n",
       "      <td>CNTS_000000000022837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>은인마켙</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>자개, 유리 등 다양한 식기류를 만나볼 수 있는 소품샵</td>\n",
       "      <td>제주특별자치도 제주시 조천읍 함덕리 1082</td>\n",
       "      <td>제주특별자치도 제주시 조천읍 함덕서2길 20</td>\n",
       "      <td>33.540661</td>\n",
       "      <td>126.663099</td>\n",
       "      <td>010-3006-7721</td>\n",
       "      <td>https://api.cdn.visitjeju.net/photomng/imgpath...</td>\n",
       "      <td>소품샵, 함덕, 잡화, 식기</td>\n",
       "      <td>CNTS_200000000015021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>뱅뱅와인마켓</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>공항 인근에 위치한 대형 와인판매점</td>\n",
       "      <td>제주특별자치도 제주시 오라이동 2171-1</td>\n",
       "      <td>제주특별자치도 제주시 사평2길 9</td>\n",
       "      <td>33.492220</td>\n",
       "      <td>126.510559</td>\n",
       "      <td>064-746-4141</td>\n",
       "      <td>https://api.cdn.visitjeju.net/photomng/imgpath...</td>\n",
       "      <td>샴페인, 오라동, 와인, 제주시내</td>\n",
       "      <td>CNTS_200000000014989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    title category                                       introduction  \\\n",
       "0      미유       쇼핑                                  숲속 별장처럼 꾸며진 소품 가게   \n",
       "1    마야블루       쇼핑  마야블루는 제주 시내의 주택가 사이에 작은 간판으로 자신의 존재를 알리고 있다. 이...   \n",
       "2   몸냥공작소       쇼핑                                귀엽고 제주스러운 유니크한 소품가게   \n",
       "3    은인마켙       쇼핑                     자개, 유리 등 다양한 식기류를 만나볼 수 있는 소품샵   \n",
       "4  뱅뱅와인마켓       쇼핑                                공항 인근에 위치한 대형 와인판매점   \n",
       "\n",
       "                       address                roadaddress   latitude  \\\n",
       "0    제주특별자치도 제주시 한림읍 옹포리 326-3  제주특별자치도 제주시 한림읍 한림상로 15-5  33.405636   \n",
       "1      제주특별자치도 제주시 노형동 1052-27       제주특별자치도 제주시 월랑로6길 21  33.489570   \n",
       "2  제주특별자치도 제주시 애월읍 유수암리 2503-1    제주특별자치도 제주시 애월읍 하소로 595  33.430614   \n",
       "3     제주특별자치도 제주시 조천읍 함덕리 1082   제주특별자치도 제주시 조천읍 함덕서2길 20  33.540661   \n",
       "4      제주특별자치도 제주시 오라이동 2171-1         제주특별자치도 제주시 사평2길 9  33.492220   \n",
       "\n",
       "    longitude         phoneno  \\\n",
       "0  126.256762  0507-1349-9322   \n",
       "1  126.478593   010-8515-2470   \n",
       "2  126.397470              --   \n",
       "3  126.663099   010-3006-7721   \n",
       "4  126.510559    064-746-4141   \n",
       "\n",
       "                                             imgpath  \\\n",
       "0  https://api.cdn.visitjeju.net/photomng/imgpath...   \n",
       "1  https://api.cdn.visitjeju.net/photomng/imgpath...   \n",
       "2  https://api.cdn.visitjeju.net/photomng/imgpath...   \n",
       "3  https://api.cdn.visitjeju.net/photomng/imgpath...   \n",
       "4  https://api.cdn.visitjeju.net/photomng/imgpath...   \n",
       "\n",
       "                                                 tag            contentsid  \n",
       "0              핸드메이드소품, 키링, 우산, 한림, 옹포리, 소품샵, 지갑, 쇼핑  CNTS_200000000015086  \n",
       "1  악세사리, 쇼핑,라탄,원데이클래스,관광기념품,상점/상가, 쇼핑,라탄,원데이클래스,카...  CNTS_200000000007334  \n",
       "2              공방,기념품,,아주 어려움, 공방,기념품,쇼핑,관광기념품,상점/상가  CNTS_000000000022837  \n",
       "3                                    소품샵, 함덕, 잡화, 식기  CNTS_200000000015021  \n",
       "4                                 샴페인, 오라동, 와인, 제주시내  CNTS_200000000014989  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "\n",
    "# 여기서 이용할 컬럼은 contentsid 하나."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           0\n",
       "category        0\n",
       "introduction    0\n",
       "address         0\n",
       "roadaddress     0\n",
       "latitude        0\n",
       "longitude       0\n",
       "phoneno         0\n",
       "imgpath         2\n",
       "tag             0\n",
       "contentsid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contentsid를 이용해 검색하여 해당 이름을 불러올 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNTS_200000000015086'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cocntentsid = df[['title','contentsid']]\n",
    "df_cocntentsid['contentsid'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미유'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cocntentsid['title'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> contentsid를 통해 검색을 할것. 그러나 title이 뭔지는 알아야하니깐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 검색할 항목 정리\n",
    "- https://www.visitjeju.net/kr/detail/view?contentsid=\n",
    "- df_contentsid['contentsid'][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어떻게 추가할까?\n",
    "- df_contentsid 데이터프레임에 새로운 컬럼을 만들어 붙디던가,\n",
    "- 새로운 데이터 프레임을 만들어 크롤링한 데이터를 저장하고 df_contentsid랑 합치던가.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNTS_000000000019679'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cocntentsid['contentsid'][2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링 할 데이터 정리\n",
    "- class \"inner_wrap\" 데이터(상단 데이터) - 상단 이미지 데이터의 경우 이미 있는 imgPath와 동일하기 때문에 필요 없음.\n",
    "    - title \"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[1]/h3\"\n",
    "    - 별점 \"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[3]/p\"\n",
    "    - mainTag(해당 관광지를 분류 가능) \n",
    "    \"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[1]\"\n",
    "        //*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[1]/a[1]\n",
    "        //*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[1]/a[2]\n",
    "        //*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[1]/a[3]\n",
    "    - subTag(해당 관광지를 조금더 디테일하게 설명 )\n",
    "    \"//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[2]\"\n",
    "        //*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[2]/a[1]\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        //*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[2]/a[7]\n",
    "\n",
    "- class \"add2020_detail_left\" 데이터(본문내용 좌측데이터 = 상세정보)\n",
    "    - image 규칙이 없음. 있긴한데 div[3]에는 text가 있고 1,2,4,5에는 이미지가 있고, \n",
    "        - //*[@id=\"tab0\"]/div/div[1]/div[1]/div/div/div/div/img\n",
    "        - //*[@id=\"tab0\"]/div/div[1]/div[2]/div/div/div/div[1]/img\n",
    "        - //*[@id=\"tab0\"]/div/div[1]/div[2]/div/div/div/div[2]/img\n",
    "        - //*[@id=\"tab0\"]/div/div[1]/div[4]/div/div/div/div/img\n",
    "        - //*[@id=\"tab0\"]/div/div[1]/div[5]/div/div/div/div/img\n",
    "    - text\n",
    "        - 와 텍스트가 html언어네 이거 어케 긁어오지? 한번에 긁어올 수 있는 방법 필요.\n",
    "        //*[@id=\"tab0\"]/div/div[1]/div[3]/div/div/div\n",
    "\n",
    "- class \"add2020_detail_right\" 중 이용안내 파트만 긁어오기. 왜냐하면 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롬 켜기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome Browser 와 Chrome Driver Version 확인하기\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service = Service(ChromeDriverManager().install()),options = chrome_options)\n",
    "driver.get(f\"https://www.visitjeju.net/kr/detail/view?contentsid={df_cocntentsid['contentsid'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 수집 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================현재 page : 0, title : 미유====================\n",
      "=================현재 page : 1, title : 마야블루====================\n",
      "=================현재 page : 2, title : 몸냥공작소====================\n",
      "=================현재 page : 3, title : 은인마켙====================\n",
      "=================현재 page : 4, title : 뱅뱅와인마켓====================\n",
      "=================현재 page : 5, title : 책은 선물====================\n",
      "=================현재 page : 6, title : 낭만와인샵====================\n",
      "=================현재 page : 7, title : 소소한 상상점====================\n",
      "=================현재 page : 8, title : 호끄만거====================\n",
      "=================현재 page : 9, title : 제주그림====================\n"
     ]
    }
   ],
   "source": [
    "# 본 코드\n",
    "mainUrl= \"https://www.visitjeju.net/kr/detail/view?contentsid=\"\n",
    "contentsid = df_cocntentsid['contentsid']\n",
    "# 크롤링 설정\n",
    "idx = 0 # 크롤링할 데이터 총 갯수\n",
    "failed_idx = 0 # 크롤링 실패시 1 증가\n",
    "\n",
    "t = random.randrange(1,2)\n",
    "\n",
    "# 크롤링할 데이터 담길 곳(header, body_left, body_right)\n",
    "    # header (title, stars, mainTag, subTag)\n",
    "scrapy_header = pd.DataFrame(columns=['title', 'stars', 'mainTag', 'subTag'])\n",
    "    # body_left (additional_image, mainText)\n",
    "scrapy_left = pd.DataFrame(columns=['additionalImage', 'mainText'])\n",
    "    # body_right (subInformTitle == dt, subInformText == dd)\n",
    "scrapy_right = pd.DataFrame(columns=['subInformTitle', 'subInformText'])\n",
    "\n",
    "\n",
    "# 본문 크롤링\n",
    "for index, contentName in enumerate(contentsid[0:10]):\n",
    "    print(f\"=================현재 page : {index}, title : {df_cocntentsid['title'][index]}====================\")\n",
    "    driver.get(f\"{mainUrl}{contentsid[index]}\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # header 크롤링 할 element\n",
    "    headerSelector = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[1]/div[1]')\n",
    "    try:\n",
    "        header_title = headerSelector.find_elements(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[1]/h3')\n",
    "        header_stars = headerSelector.find_elements(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[3]/p')\n",
    "        header_mainTag = headerSelector.find_elements(By.CLASS_NAME, \"best_tag\")\n",
    "        header_subTag = headerSelector.find_elements(By.CSS_SELECTOR, 'div.sub_info_area > div.tag_area > p:nth-child(2) > a')\n",
    "        for\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 연습코드\n",
    "# import requests\n",
    "# from lxml import html\n",
    "\n",
    "# # 크롤링할 웹페이지 URL 설정\n",
    "# url = 'https://www.visitjeju.net/kr/detail/view?contentsid=CNTS_000000000019279'\n",
    "# driver.get(url)\n",
    "# scrapy_data = pd.DataFrame(columns=['text1', 'image1'])\n",
    "\n",
    "# text1 = []\n",
    "# image1 = []\n",
    "\n",
    "\n",
    "\n",
    "# try:\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "#     dl_tag = soup.find('dl')\n",
    "#     # 텍스트 가져오기\n",
    "#     text_element = soup.find('div', class_='wrap_contView')\n",
    "#     text = text_element.get_text(strip=True)\n",
    "    \n",
    "#     # 이미지 가져오기\n",
    "#     image_element = soup.find('div', class_='swiper-slide')\n",
    "#     image_url = image_element.find('img')['src']\n",
    "    \n",
    "#     # 데이터프레임에 저장\n",
    "#     data = {'text1': [text], 'image1': [image_url]}\n",
    "#     scrapy_data = pd.DataFrame(data)\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# # 크롤링할 웹페이지 URL 설정\n",
    "# url = 'https://www.visitjeju.net/kr/detail/view?contentsid=CNTS_000000000019279'\n",
    "\n",
    "# # 웹페이지에 GET 요청 보내고 HTML 가져오기\n",
    "# response = requests.get(url)\n",
    "# html = response.text\n",
    "\n",
    "# try:\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "#     # dl 태그 찾기\n",
    "#     dl_tag = soup.find('dl')\n",
    "    \n",
    "#     if dl_tag:\n",
    "#         # 텍스트와 이미지를 저장할 변수 초기화\n",
    "#         text1 = \"\"\n",
    "#         image1 = None\n",
    "        \n",
    "#         # dt와 dd 태그를 모두 찾아서 반복문으로 순회\n",
    "#         for dt_tag, dd_tag in zip(dl_tag.find_all('dt'), dl_tag.find_all('dd')):\n",
    "#             # dt 태그의 텍스트 추출 (제목)\n",
    "#             dt_text = dt_tag.get_text(strip=True)\n",
    "#             # dd 태그의 텍스트 추출 (상세 내용)\n",
    "#             dd_text = dd_tag.get_text(strip=True)\n",
    "            \n",
    "#             # 상세 내용에 이미지가 있는지 확인\n",
    "#             img_tag = dd_tag.find('img')\n",
    "#             if img_tag:\n",
    "#                 # 이미지의 src 속성 값 추출\n",
    "#                 image1 = img_tag.get('src')\n",
    "            \n",
    "#             # dt 태그의 텍스트와 dd 태그의 텍스트를 합쳐서 저장\n",
    "#             if dt_text:\n",
    "#                 text1 += f\"{dt_text}: {dd_text}\\n\"\n",
    "        \n",
    "#         # 데이터프레임에 저장\n",
    "#         data = {'text1': [text1], 'image1': [image1]}\n",
    "#         scrapy_data = pd.DataFrame(data)\n",
    "#     else:\n",
    "#         print(\"dl 태그를 찾을 수 없습니다.\")\n",
    "# except Exception as e:\n",
    "#     print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 크롤링할 웹페이지 URL 설정\n",
    "# url = 'https://www.visitjeju.net/kr/detail/view?contentsid=CNTS_000000000019279'\n",
    "# driver.get(url)\n",
    "\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "# # # dl 태그 찾기\n",
    "# # XPath로 dl 태그 찾기\n",
    "# dl_element = driver.find_element(By.XPATH,\"/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div[2]/div[2]/div\")\n",
    "# try:\n",
    "#     # dt = title\n",
    "#     dt_elements = dl_element.find_elements(By.TAG_NAME, \"dt\")\n",
    "#     # dd = detail\n",
    "#     dd_elements = dl_element.find_elements(By.TAG_NAME, \"dd\")\n",
    "\n",
    "#     for dt, dd in zip(dt_elements, dd_elements):\n",
    "#         print(f\"{dt.text}-{dd.text}\")\n",
    "    \n",
    "\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "#     print('크롤링 실패')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd_elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*[@id=\"content\"]/div[2]/div[2]/div[2]/div[2]/div[2]/div\n",
    "# //*[@id=\"content\"]/div[2]/div[2]/div[2]/div[2]/div[2]/div/dl/dt[1] #소개\n",
    "# //*[@id=\"content\"]/div[2]/div[2]/div[2]/div[2]/div[2]/div/dl/dd[1]/text() #관광지와 가까운 마니주펜션\n",
    "# //*[@id=\"content\"]/div[2]/div[2]/div[2]/div[2]/div[2]/div/dl/dt[2] #이용시간\n",
    "# //*[@id=\"content\"]/div[2]/div[2]/div[2]/div[2]/div[2]/div/dl/dd[2]/text()\n",
    "\n",
    "# //*[@id=\"content\"]/div[2]/div[2]/div[2]/div[2]/div[2]/div/dl/dd[3] #공용주차장..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 크롤링할 웹페이지 URL 설정\n",
    "# url = 'https://www.visitjeju.net/kr/detail/view?contentsid=CNTS_000000000019279'\n",
    "# driver.get(url)\n",
    "\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "# # # dl 태그 찾기\n",
    "# # XPath로 dl 태그 찾기\n",
    "# # test_element = driver.find_element(By.XPATH, \"/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div[2]/div[2]\")\n",
    "# dl_element = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div[2]/div[2]/div')\n",
    "# try:\n",
    "#     # dt = title\n",
    "#     dt_elements_save = []\n",
    "#     # dt_elements = dl_element.find_elements(By.TAG_NAME, \"//dl/dt\")\n",
    "#     dt_elements = dl_element.find_elements(By.XPATH, \"/dl/dt\")\n",
    "#     # dd = detail\n",
    "#     dd_elements_save = []\n",
    "#     dd_elements = dl_element.find_elements(By.XPATH, \"/dl/dd\")\n",
    "\n",
    "#     for idx, dt, dd in zip(dt_elements, dd_elements):\n",
    "#         idx + 1\n",
    "#         dt_elements_save.append(dt[idx])\n",
    "#         dd_elements_save.append(dd[idx])\n",
    "#         print(f\"{dt.text}-{dd.text}\")\n",
    "    \n",
    "\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "#     print('크롤링 실패')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================현재 page : 0, title : 미유====================\n",
      "미유 - 별점(별점없음)\n",
      "main태그0: #한림, main태그0: #옹포리, main태그0: #소품샵\n",
      "sub태그0 : #핸드메이드소품\n",
      "sub태그0 : #키링\n",
      "sub태그0 : #우산\n",
      "sub태그0 : #지갑\n",
      "sub태그0 : #쇼핑\n",
      "=================현재 page : 1, title : 마야블루====================\n",
      "마야블루 - 별점(별점없음)\n",
      "main태그1: #쇼핑, main태그1: #라탄, main태그1: #원데이클래스\n",
      "sub태그1 : #관광기념품\n",
      "sub태그1 : #상점/상가\n",
      "=================현재 page : 2, title : 몸냥공작소====================\n",
      "몸냥공작소 - 별점(별점없음)\n",
      "main태그2: #공방, main태그2: #기념품, main태그2: #쇼핑\n",
      "sub태그2 : #관광기념품\n",
      "sub태그2 : #상점/상가\n",
      "=================현재 page : 3, title : 은인마켙====================\n",
      "은인마켙 - 별점(별점없음)\n",
      "main태그3: #함덕, main태그3: #소품샵, main태그3: #식기\n",
      "sub태그3 : #잡화\n",
      "=================현재 page : 4, title : 뱅뱅와인마켓====================\n",
      "뱅뱅와인마켓 - 별점(별점없음)\n",
      "main태그4: #제주시내, main태그4: #오라동, main태그4: #와인\n",
      "sub태그4 : #샴페인\n",
      "=================현재 page : 5, title : 책은 선물====================\n",
      "책은 선물 - 별점(별점없음)\n",
      "main태그5: #한경면, main태그5: #신창리, main태그5: #서점\n",
      "sub태그5 : #책방\n",
      "=================현재 page : 6, title : 낭만와인샵====================\n",
      "낭만와인샵 - 별점(별점없음)\n",
      "main태그6: #제주시내, main태그6: #용담, main태그6: #와인\n",
      "sub태그6 : #와인샵\n",
      "=================현재 page : 7, title : 소소한 상상점====================\n",
      "소소한 상상점 - 별점(별점없음)\n",
      "main태그7: #구좌읍, main태그7: #평대리, main태그7: #소품샵\n",
      "sub태그7 : #핸드메이드\n",
      "sub태그7 : #잡화\n",
      "sub태그7 : #액세서리\n",
      "=================현재 page : 8, title : 호끄만거====================\n",
      "호끄만거 - 별점(별점없음)\n",
      "main태그8: #제주시내, main태그8: #동문시장, main태그8: #소품샵\n",
      "sub태그8 : #엽서\n",
      "sub태그8 : #디퓨저\n",
      "sub태그8 : #핸드크림\n",
      "sub태그8 : #액세서리\n",
      "=================현재 page : 9, title : 제주그림====================\n",
      "제주그림 - 별점(별점없음)\n",
      "main태그9: #쇼핑, main태그9: #휴식/힐링, main태그9: #관광기념품\n",
      "sub태그9 : #상점/상가\n"
     ]
    }
   ],
   "source": [
    "# 본 코드\n",
    "mainUrl= \"https://www.visitjeju.net/kr/detail/view?contentsid=\"\n",
    "contentsid = df_cocntentsid['contentsid']\n",
    "# 크롤링 설정\n",
    "idx = 0 # 크롤링할 데이터 총 갯수\n",
    "failed_idx = 0 # 크롤링 실패시 1 증가\n",
    "\n",
    "t = random.randrange(1,2)\n",
    "\n",
    "# 크롤링할 데이터 담길 곳(header, body_left, body_right)\n",
    "    # header (title, stars, mainTag, subTag)\n",
    "scrapy_header = pd.DataFrame(columns=['title', 'stars', 'mainTag', 'subTag'])\n",
    "    # body_left (additional_image, mainText)\n",
    "scrapy_left = pd.DataFrame(columns=['additionalImage', 'mainText'])\n",
    "    # body_right (subInformTitle == dt, subInformText == dd)\n",
    "scrapy_right = pd.DataFrame(columns=['subInformTitle', 'subInformText'])\n",
    "\n",
    "\n",
    "# 본문 크롤링\n",
    "for index, contentName in enumerate(contentsid[0:10]):\n",
    "    print(f\"=================현재 page : {index}, title : {df_cocntentsid['title'][index]}====================\")\n",
    "    driver.get(f\"{mainUrl}{contentsid[index]}\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # header 크롤링\n",
    "    headerSelector = driver.find_element(By.XPATH, '/html/body/div/div[2]/div/div[2]/div[2]/div/div/div[2]/div[1]/div[1]')\n",
    "    try:\n",
    "        header_title = headerSelector.find_elements(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[1]/h3')\n",
    "        header_stars = headerSelector.find_elements(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[3]/p')\n",
    "        header_mainTag = headerSelector.find_elements(By.CLASS_NAME, \"best_tag\")\n",
    "        # header_subTag = headerSelector.find_elements(By.XPATH, '//p[@data-v-51160e04]')\n",
    "        header_subTag = headerSelector.find_elements(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/div[1]/div[2]/div[4]/p[2]')\n",
    "        # title, stars\n",
    "        for h_title, h_stars in zip(header_title, header_stars):\n",
    "            print(h_title.text,\"-\", h_stars.text)\n",
    "\n",
    "        # mainTag\n",
    "        for midx, h_mainTag in enumerate(header_mainTag):\n",
    "            # 태그 분리\n",
    "            tags = h_mainTag.text.split(\"#\")\n",
    "            tags = [f\"main태그{index}: #{tag.strip()}\" for tag in tags if tag.strip()]  # \"#\"을 다시 추가하여 태그 리스트 작성\n",
    "            print(\", \".join(tags))  # 분리된 태그들을 출력\n",
    "        # subTag\n",
    "        for midx, h_subTag in enumerate(header_subTag):\n",
    "            stags = h_subTag.find_elements(By.TAG_NAME, 'a')\n",
    "            for stag in stags:\n",
    "                print(f\"sub태그{index} : {stag.text}\")\n",
    "            \n",
    "            \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"헤더 크롤링 실패\")\n",
    "    \n",
    "    # # body_left 크롤링\n",
    "    # bodyLeftSelector = \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['태그1: #쇼핑', '태그1: #휴식/힐링', '태그1: #관광기념품']\n"
     ]
    }
   ],
   "source": [
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
